{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import delf as df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os.path as path\n",
    "\n",
    "modulos_path = path.abspath('../minIA')\n",
    "if modulos_path not in sys.path:\n",
    "    sys.path.append(modulos_path)\n",
    "\n",
    "from utiles import lectura_img\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import argparse\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "from six.moves import range\n",
    "import tensorflow as tf\n",
    "\n",
    "from google.protobuf import text_format\n",
    "from tensorflow.python.platform import app\n",
    "from delf import delf_config_pb2\n",
    "from delf import feature_io\n",
    "from delf import utils\n",
    "from delf import extractor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/tensorflow/models/blob/master/research/delf/delf/python/examples/extract_features.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Original example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(image_paths, config_path, output_dir):\n",
    "  # Read list of images.\n",
    "  print('Reading list of images...')\n",
    "  num_images = len(image_paths)\n",
    "  print(f'done! Found {num_images} images')\n",
    "\n",
    "  # Parse DelfConfig proto.\n",
    "  config = delf_config_pb2.DelfConfig()\n",
    "  with tf.io.gfile.GFile(config_path, 'r') as f:\n",
    "    text_format.Merge(f.read(), config)\n",
    "\n",
    "  # Create output directory if necessary.\n",
    "  if not tf.io.gfile.exists(output_dir):\n",
    "    tf.io.gfile.makedirs(output_dir)\n",
    "\n",
    "  extractor_fn = extractor.MakeExtractor(config)\n",
    "\n",
    "  start = time.time()\n",
    "  for i in range(num_images):\n",
    "    # Report progress once in a while.\n",
    "    if i == 0:\n",
    "      print('Starting to extract DELF features from images...')\n",
    "    elif i % _STATUS_CHECK_ITERATIONS == 0:\n",
    "      elapsed = (time.time() - start)\n",
    "      print(\n",
    "          f'Processing image {i} out of {num_images}, last '\n",
    "          f'{_STATUS_CHECK_ITERATIONS} images took {elapsed} seconds'\n",
    "      )\n",
    "      start = time.time()\n",
    "\n",
    "    # If descriptor already exists, skip its computation.\n",
    "    out_desc_filename = os.path.splitext(os.path.basename(\n",
    "        image_paths[i]))[0] + _DELF_EXT\n",
    "    out_desc_fullpath = os.path.join(output_dir, out_desc_filename)\n",
    "    if tf.io.gfile.exists(out_desc_fullpath):\n",
    "      print(f'Skipping {image_paths[i]}')\n",
    "      continue\n",
    "\n",
    "    im = np.array(utils.RgbLoader(image_paths[i]))\n",
    "\n",
    "    # Extract and save features.\n",
    "    extracted_features = extractor_fn(im)\n",
    "    locations_out = extracted_features['local_features']['locations']\n",
    "    descriptors_out = extracted_features['local_features']['descriptors']\n",
    "    feature_scales_out = extracted_features['local_features']['scales']\n",
    "    attention_out = extracted_features['local_features']['attention']\n",
    "\n",
    "    feature_io.WriteToFile(out_desc_fullpath, locations_out, feature_scales_out,\n",
    "                           descriptors_out, attention_out)\n",
    "    return descriptors_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extension of feature files.\n",
    "_DELF_EXT = '.delf'\n",
    "# Pace to report extraction log.\n",
    "_STATUS_CHECK_ITERATIONS = 100\n",
    "\n",
    "image_paths = lectura_img('D:\\Archivos\\Proyectos\\minIA\\images\\GrupoDELF')\n",
    "config_path = 'D:\\Archivos\\Proyectos\\minIA\\\\notebooks\\delf_config_example.pbtxt'\n",
    "output_dir = 'D:\\Archivos\\Proyectos\\minIA\\descriptors\\delf'\n",
    "descrip = main(image_paths, config_path,output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modificación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import cv2 as cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pace to report extraction log.\n",
    "_STATUS_CHECK_ITERATIONS = 10\n",
    "\n",
    "def extractorDELF(image_dir, config_path, output_dir, name_pickle):\n",
    "    \n",
    "  # Read list of images.\n",
    "    print('Reading list of images...')\n",
    "    image_paths = lectura_img(image_dir)\n",
    "    num_images = len(image_paths)\n",
    "    print(f'Done! Found {num_images} images')\n",
    "\n",
    "  # Parse DelfConfig proto.\n",
    "    config = delf_config_pb2.DelfConfig()\n",
    "    with tf.io.gfile.GFile(config_path, 'r') as f:\n",
    "        text_format.Merge(f.read(), config)\n",
    "\n",
    "  # Create output directory if necessary.\n",
    "    if not tf.io.gfile.exists(output_dir):\n",
    "        tf.io.gfile.makedirs(output_dir)\n",
    "    \n",
    "  #Create pickle file\n",
    "    path_pickle = path.abspath(output_dir+'//'+name_pickle)\n",
    "    pickle_file = open(path_pickle, 'wb')\n",
    "\n",
    "  #Create lista de descriptor por imagen\n",
    "    descriptors = list()\n",
    "    \n",
    "  #Crea el extractor\n",
    "    extractor_fn = extractor.MakeExtractor(config)\n",
    "\n",
    "    start = time.time()\n",
    "    for i in range(num_images):\n",
    "    # Report progress once in a while.\n",
    "        if i == 0:\n",
    "            print('Starting to extract DELF features from images...')\n",
    "        elif i % _STATUS_CHECK_ITERATIONS == 0:\n",
    "            elapsed = (time.time() - start)\n",
    "            print(\n",
    "                f'Processing image {i} out of {num_images}, last '\n",
    "                f'{_STATUS_CHECK_ITERATIONS} images took {elapsed} seconds'\n",
    "            )\n",
    "            start = time.time()\n",
    "            \n",
    "      #Carga las imágenes\n",
    "        im = np.array(utils.RgbLoader(image_paths[i]))\n",
    "\n",
    "      # Extract features.\n",
    "        extracted_features = extractor_fn(im)\n",
    "        \n",
    "      # Save features.\n",
    "        nom_img = path.split(image_paths[i])[1]\n",
    "        extracted_features['local_features']['name_img'] = nom_img\n",
    "        descriptors.append(extracted_features['local_features'])\n",
    "    pickle.dump(descriptors, pickle_file)\n",
    "    print(\"Termino\")\n",
    "    return descriptors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading list of images...\n",
      "Done! Found 41 images\n",
      "Starting to extract DELF features from images...\n",
      "Processing image 10 out of 41, last 10 images took 11.350126266479492 seconds\n",
      "Processing image 20 out of 41, last 10 images took 11.449545860290527 seconds\n",
      "Processing image 30 out of 41, last 10 images took 10.341138124465942 seconds\n",
      "Processing image 40 out of 41, last 10 images took 7.801088333129883 seconds\n",
      "Termino\n"
     ]
    }
   ],
   "source": [
    "#Output incluye el nombre del archivo\n",
    "image_dir = 'D:\\Archivos\\Proyectos\\minIA\\images\\GrupoDELF'\n",
    "config_path = 'D:\\Archivos\\Proyectos\\minIA\\\\notebooks\\delf_config_example.pbtxt'\n",
    "output_dir = 'D:\\Archivos\\Proyectos\\minIA\\descriptors\\delf\\PruebaD1'\n",
    "name_pickle = 'pruebaDELF-08-10-20.pickle'\n",
    "descrip = extractorDELF(image_dir, config_path, output_dir, name_pickle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rutas de búsqueda de imágenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Llaves de descriptores:\n",
      " dict_keys(['locations', 'descriptors', 'scales', 'attention', 'name_img']) \n",
      "\n",
      "Descriptores encontrados por imagen:\n",
      "20-21-19-26-24-20-20-28-23-34-28-13-19-40-17-14-49-7-77-26-20-41-28-32-22-44-31-35-23-37-21-21-8-11-29-25-193-207-140-284-266-\n",
      "\n",
      "Tamaño de cada KeyPoint:\n",
      "20-21-19-26-24-20-20-28-23-34-28-13-19-40-17-14-49-7-77-26-20-41-28-32-22-44-31-35-23-37-21-21-8-11-29-25-193-207-140-284-266-\n",
      "\n",
      "Tamaño de cada descriptor imagen uno:\n",
      "40-40-40-40-40-40-40-40-40-40-40-40-40-40-40-40-40-40-40-40-\n",
      "\n",
      "Puntuación de cada descriptr de la imagen uno\n",
      "[191.81944 173.71945 161.15355 153.3822  140.13965 139.81908 138.38896\n",
      " 132.28749 124.10377 124.07345 122.19906 117.48806 110.6403  110.3928\n",
      " 107.89728 105.55391 104.59865 103.08346 102.44146 101.6961 ]-<class 'numpy.ndarray'>\n",
      "[[ 96.       256.      ]\n",
      " [ 90.510544 271.53162 ]\n",
      " [ 80.       256.      ]\n",
      " [ 90.51054  248.90399 ]\n",
      " [416.        64.      ]\n",
      " [ 96.       256.      ]\n",
      " [352.         0.      ]\n",
      " [  0.       288.      ]\n",
      " [192.       160.      ]\n",
      " [224.       384.      ]\n",
      " [192.       176.      ]\n",
      " [203.64871  181.02109 ]\n",
      " [362.04218    0.      ]\n",
      " [ 48.       400.      ]\n",
      " [ 16.       400.      ]\n",
      " [384.       224.      ]\n",
      " [203.64871  158.39345 ]\n",
      " [240.       240.      ]\n",
      " [352.         0.      ]\n",
      " [208.       176.      ]]\n"
     ]
    }
   ],
   "source": [
    "print(f'Llaves de descriptores:\\n {descrip[0].keys()} \\n')\n",
    "\n",
    "print('Descriptores encontrados por imagen:')\n",
    "for i in range(len(descrip)):\n",
    "    print(len(descrip[i]['descriptors']), end='-' )\n",
    "    \n",
    "print('\\n\\nTamaño de cada KeyPoint:')\n",
    "for i in range(len(descrip)):\n",
    "    print(len(descrip[i]['scales']), end='-' )\n",
    "    \n",
    "print('\\n\\nTamaño de cada descriptor imagen uno:')\n",
    "for i in range(len(descrip[0]['descriptors'])):\n",
    "    print(len(descrip[0]['descriptors'][i]), end='-' )\n",
    "    \n",
    "print('\\n\\nPuntuación de cada descriptr de la imagen uno')\n",
    "print(descrip[0]['attention'], end='-' )\n",
    "\n",
    "print(type(descrip[0]['descriptors']))\n",
    "\n",
    "print(descrip[0]['locations'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creación de puntos de interés"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Recibe lista de keypoints de una imagen\n",
    "def genKeyPoints( kp_img ):\n",
    "    keypoints = list()\n",
    "    for kp in kp_img:\n",
    "        keypoints.append(cv.KeyPoint(kp[1], kp[0], 5))\n",
    "    return keypoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100008.jpg min: (96.0, 90.510544)  max: (256.0, 271.53162)\n",
      "100023.jpg min: (135.76581, 128.0)  max: (271.53162, 288.0)\n",
      "100053.jpg min: (0.0, 112.0)  max: (181.02107, 128.0)\n",
      "100078.jpg min: (22.627632, 22.627632)  max: (384.6698, 158.39345)\n",
      "100090.jpg min: (0.0, 0.0)  max: (384.0, 384.6698)\n",
      "100122.jpg min: (158.39345, 181.02109)  max: (362.04218, 203.64871)\n",
      "100123.jpg min: (135.76581, 336.0)  max: (339.41452, 352.0)\n",
      "100128.jpg min: (192.0, 32.0)  max: (384.0, 96.0)\n",
      "100134.jpg min: (80.0, 203.64871)  max: (208.0, 248.90399)\n",
      "100143.jpg min: (256.0, 128.0)  max: (256.0, 256.0)\n",
      "100150.jpg min: (0.0, 158.39345)  max: (90.510544, 181.02109)\n",
      "100157.jpg min: (160.0, 16.0)  max: (224.0, 256.0)\n",
      "100187.jpg min: (48.0, 48.0)  max: (80.0, 144.0)\n",
      "100204.jpg min: (224.0, 32.0)  max: (288.0, 80.0)\n",
      "100237.jpg min: (22.627632, 22.627632)  max: (45.255272, 181.02109)\n",
      "100259.jpg min: (32.0, 224.0)  max: (224.0, 384.0)\n",
      "100263.jpg min: (90.51054, 176.0)  max: (248.90399, 352.0)\n",
      "100288.jpg min: (226.27635, 135.76581)  max: (294.15924, 226.27635)\n",
      "100295.jpg min: (0.0, 0.0)  max: (96.0, 90.510544)\n",
      "100322.jpg min: (64.0, 16.0)  max: (192.0, 16.0)\n",
      "100335.jpg min: (16.0, 224.0)  max: (368.0, 256.0)\n",
      "100367.jpg min: (0.0, 0.0)  max: (90.510544, 90.51054)\n",
      "100380.jpg min: (192.0, 64.0)  max: (192.0, 64.0)\n",
      "100382.jpg min: (0.0, 45.255264)  max: (361.99097, 316.7869)\n",
      "100383.jpg min: (22.627632, 240.0)  max: (90.51054, 384.0)\n",
      "100402.jpg min: (80.0, 128.0)  max: (208.0, 320.0)\n",
      "100428.jpg min: (0.0, 0.0)  max: (45.255272, 48.0)\n",
      "100434.jpg min: (0.0, 160.0)  max: (320.0, 352.0)\n",
      "100444.jpg min: (112.0, 16.0)  max: (240.0, 160.0)\n",
      "100445.jpg min: (16.0, 16.0)  max: (240.0, 256.0)\n",
      "100458.jpg min: (0.0, 0.0)  max: (271.53162, 272.0)\n",
      "100474.jpg min: (226.27635, 224.0)  max: (226.27635, 224.0)\n",
      "100479.jpg min: (320.0, 320.0)  max: (416.0, 384.0)\n",
      "100506.jpg min: (32.0, 135.76581)  max: (416.0, 226.27635)\n",
      "100513.jpg min: (271.53162, 272.0)  max: (294.15924, 288.0)\n",
      "100520.jpg min: (90.51054, 64.0)  max: (113.138176, 288.0)\n",
      "a0010.jpg min: (128.0, 64.0)  max: (128.0, 128.0)\n",
      "a205062.jpg min: (90.49774, 64.0)  max: (180.99548, 192.0)\n",
      "a212017.jpg min: (64.0, 90.49774)  max: (128.0, 90.49774)\n",
      "a212018.jpg min: (90.49774, 90.510544)  max: (180.99548, 135.76581)\n",
      "a79094.jpg min: (0.0, 0.0)  max: (64.0, 90.49774)\n"
     ]
    }
   ],
   "source": [
    "desc_muestras = descrip\n",
    "\n",
    "for ima in desc_muestras:\n",
    "        imagen = path.abspath(image_dir+'\\\\'+ima['name_img'])\n",
    "        mini = (min(ima['locations'][0]), min(ima['locations'][1]) )\n",
    "        maxi = (max(ima['locations'][0]), max(ima['locations'][1]))\n",
    "        print(ima['name_img'], 'min:', mini,' max:', maxi)\n",
    "        img = cv.imread(imagen)\n",
    "        gray= cv.cvtColor(img,cv.COLOR_BGR2GRAY)\n",
    "        keypoints = genKeyPoints(ima['locations'])\n",
    "        img=cv.drawKeypoints(gray,keypoints,img,flags=cv.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
    "        cv.imwrite(output_dir+'\\\\'+ima['name_img'],img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "skimage import feature"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
