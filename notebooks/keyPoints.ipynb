{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejecutar las siguientes líneas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from os import path, mkdir, listdir, chdir\n",
    "import pickle\n",
    "import cv2 as cv\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact, interact_manual\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import io\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "modulos_path = path.abspath('../minIA')\n",
    "if modulos_path not in sys.path:\n",
    "    sys.path.append(modulos_path)\n",
    "    \n",
    "from utiles import lectura_img\n",
    "import random\n",
    "random.seed(42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Recibe lista de keypoints de una imagen, crea los objetos KP de openCV\n",
    "def genKeyPoints( kp_img ):\n",
    "    keypoints = list()\n",
    "    for kp in kp_img:\n",
    "        keypoints.append(cv.KeyPoint(kp[0], kp[1], kp[2]))\n",
    "    return keypoints"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualización tópicos\n",
    "\n",
    "El siguiente codigo carga los tópicos y elementos de la figura para mostrar los archivos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa7cce0744c7476bb5a78cb105d39238",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='topics_path', options=(('index_inv_full_dataset_v2_SIFT.r4l10000o0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@interact_manual\n",
    "def load_topicos(\n",
    "    topics_path=[(file,path.join(\"/media/working/minia/minhash/\",file)) for file in listdir(\"/media/working/minia/minhash/\") if file.endswith(\".models\")],\n",
    "    centXimg='/media/working/minia/descriptores/labels_full_dataset_v2_SIFT.pickle',\n",
    "    descr_kp='/media/working/minia/descriptores/full_dataset_v2_SIFT.pickle', \n",
    "    image_dir='/media/working/minia/images/images_training_rev1/'):\n",
    "    global topics\n",
    "    global len_topics\n",
    "    global images_descr\n",
    "    global desc_kp\n",
    "    global etiquetas\n",
    "    global dir_out\n",
    "    global dir_img\n",
    "    global topics_lenght\n",
    "    \n",
    "    topics = open(topics_path, 'r')\n",
    "    topics= topics.readlines()\n",
    "    topics_lenght=[]\n",
    "    for line in topics:\n",
    "        centroides = line.strip().split()[1:]\n",
    "        centroides = [ int(cent.split(':')[0]) for cent in centroides]\n",
    "        topics_lenght.append(len(centroides))\n",
    "        \n",
    "    len_topics=len(topics)\n",
    "    \n",
    "    pickle_file = open(centXimg,'rb')\n",
    "    images_descr = pickle.load(pickle_file)\n",
    "    pickle_file.close()\n",
    "    \n",
    "    pickle_file = open(path.abspath(descr_kp), 'rb')  \n",
    "    args = pickle.load(pickle_file)\n",
    "    desc_kp = pickle.load(pickle_file)\n",
    "    pickle_file.close()\n",
    "    \n",
    "    dir_img=image_dir\n",
    "\n",
    "    print('#Topics: '+ str(len_topics))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def indicesTopicos (centroides, images_descr,threshold=0.7):\n",
    "    tam_cents = len(centroides)\n",
    "    centroides_= set(centroides) \n",
    "    img_index = 0\n",
    "    images = list()\n",
    "    for descrp in images_descr[0]:\n",
    "        descp_ = dict([(ic,i) for i,ic in enumerate(descrp)])\n",
    "        descp = set(descrp)\n",
    "        tam_descp = len(descrp)\n",
    "        inter=centroides_.intersection(descp)\n",
    "        overlap=len(inter)/min(len(centroides_),len(descp))\n",
    "        if overlap >= threshold:\n",
    "            images.append((img_index,[ descp_[ic] for ic in inter],overlap))\n",
    "        #Overlaping\n",
    "        #max_ = round( min(tam_descp, tam_cents)*.30 ) #Requiere un 30%\n",
    "        #posc_index = 0\n",
    "        #posc = list()\n",
    "        #for cent in descrp:\n",
    "        #    if cent in centroides:\n",
    "        #        posc.append(posc_index)\n",
    "        #    posc_index += 1\n",
    "        #if len(posc) > max_ : #No puede ser >= porque max_ puede ser cero\n",
    "        #    images.append((img_index ,posc)) #Añade una tupla, del indice de la imagen y los indices de los KP\n",
    "        img_index += 1\n",
    "    return images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Elegir tópico\n",
    "\n",
    "Este código permite elejir el tópico, el número de imágnes dónde buscar el código y el threshold a usar para considerar que un tópico esta presente o no en la imagen (topicos con números pequeños usar 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "088273e0d3ac430ba62d703ab2ba5dbb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='Topics', options=(('0 [size 49]', 0), ('1 [size 376]', 1), ('2 [si…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@interact_manual\n",
    "def choose_topicos(Topics=[(f\"{i} [size {z}]\",i) for i,z in zip(range(len_topics),topics_lenght)], num_imgs= (0, int(len(images_descr)/1), 5), threshold = (0.0, 1.0, 0.01)):\n",
    "    global lista_imgs\n",
    "    global num_topic\n",
    "    global name_images\n",
    "    \n",
    "    num_topic= Topics\n",
    "    centroides = topics[Topics].split()[1:]\n",
    "    centroides = [ int(cent.split(':')[0]) for cent in centroides]\n",
    "    lista_imgs = indicesTopicos (centroides, images_descr[0:num_imgs], threshold=threshold)\n",
    "    \n",
    "    imgs_index=[imgs[0] for imgs in lista_imgs]\n",
    "    aux=0\n",
    "    name_images=[]\n",
    "    for ii,i in enumerate(imgs_index):\n",
    "        imagen = path.abspath(dir_img + desc_kp[i]['name_img'])\n",
    "        name_images.append((desc_kp[i]['name_img'],aux,i,lista_imgs[ii][2]))\n",
    "        aux+=1\n",
    "        \n",
    "    print('#Images: '+str(len(lista_imgs)))\n",
    "    print('#Len topic: '+str(len(centroides)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizando ejemplos del tópico\n",
    "\n",
    "Se muestran ejemplos de imágenes que contiene el tópico seleccionado en la parte [anterior](http://minhashing.ngrok.io/notebooks/minIA/notebooks/keyPoints.ipynb#Elegir-t%C3%B3pico)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e25fe8fc614847c3abc24edef8ebd868",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='img', options=((0, ('165129.jpg', 0, 580, 0.68)), (1, ('418071.jpg…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = (10,5)\n",
    "plt.rcParams['figure.dpi'] = 160\n",
    "\n",
    "@interact\n",
    "def show_images_per_topic(img=[(aux,(img,aux,i,o)) for img,aux,i,o in name_images]):\n",
    "    img,aux,i,o=img\n",
    "    if aux-5 < 0:\n",
    "        aux=5\n",
    "    if aux+5 > len(name_images):\n",
    "        aux=len(name_images)-5\n",
    "    min_=max(0,aux-5)\n",
    "    max_=min(len(name_images),aux+5)\n",
    "    fig, axs = plt.subplots(2,5)\n",
    "    for ii in range(min_,max_):\n",
    "        img,aux,i,overlap=name_images[ii]\n",
    "        imagen = path.abspath(dir_img + img)\n",
    "        img = cv.imread(imagen)\n",
    "        gray= cv.cvtColor(img,cv.COLOR_BGR2GRAY)\n",
    "        key_points= [desc_kp[i]['keypoints'][kp] for kp in lista_imgs[aux][1]]\n",
    "        keypoints = genKeyPoints(key_points)\n",
    "        img=cv.drawKeypoints(gray,keypoints,img,color=(255,0,0),flags=cv.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
    "        x=ii-min_\n",
    "        y=x%5\n",
    "        x=int(x/5)\n",
    "        axs[x,y].set_yticklabels([])\n",
    "        axs[x,y].set_xticklabels([])\n",
    "        axs[x,y].set_xlabel(f'{ii}, {overlap:0.3}, #{i}')\n",
    "        axs[x,y].imshow(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ver una imágen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0fcabb3cdbc349f690b41d2c39b61882",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Text(value='1640', description='image'), FloatSlider(value=0.5, description='threshold',…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@interact_manual\n",
    "def choose_topicos(image=str(random.choice(range(1,len(images_descr)))),threshold = (0.0, 1.0, 0.01),text=True):\n",
    "    global lista_imgs\n",
    "    global topics\n",
    "    global name_images\n",
    "    global images_descr\n",
    "    cmap=plt.get_cmap(\"hsv\")\n",
    "\n",
    "    descrp=images_descr.iloc[int(image)][0]\n",
    "    img=images_descr.iloc[int(image)][1]\n",
    "    descp = set(descrp)\n",
    "    tam_descp = len(descrp)\n",
    "    topics_in_image= 0\n",
    "    \n",
    "    imagen = path.abspath(dir_img + img)\n",
    "    img = cv.imread(imagen)\n",
    "    gray= cv.cvtColor(img,cv.COLOR_BGR2GRAY)\n",
    "    gray= cv.cvtColor(gray,cv.COLOR_GRAY2BGR)\n",
    "    keypoints=[]\n",
    "    for topic in range(len(topics)):\n",
    "        color=tuple(int(c*256) for c in cmap(topic/len(topics))[:3])\n",
    "        centroides = topics[topic].split()[1:]\n",
    "        centroides = set([ int(cent.split(':')[0]) for cent in centroides])\n",
    "        \n",
    "        descp_ = dict([(ic,i) for i,ic in enumerate(descrp)])\n",
    "        inter=centroides.intersection(descp)\n",
    "        overlap=len(inter)/min(len(centroides),len(centroides))\n",
    "        \n",
    "        if overlap >= threshold:\n",
    "            key_points= [desc_kp[int(image)]['keypoints'][kp] for kp in [ descp_[ic] for ic in inter]]\n",
    "            keypoints_ = genKeyPoints(key_points)\n",
    "            topics_in_image+=1\n",
    "            for curKey in keypoints_:\n",
    "                x=np.int(curKey.pt[0])\n",
    "                y=np.int(curKey.pt[1])\n",
    "                size = np.int(curKey.size)\n",
    "                gray=cv.circle(gray,(x,y),size,color=color,thickness=1, lineType=0, shift=0)\n",
    "                if text:\n",
    "                    gray=cv.putText(gray,str(topic),(x,y),cv.FONT_HERSHEY_SIMPLEX ,0.3,color,1, cv.LINE_AA)\n",
    "            \n",
    "    plt.imshow(gray, cmap=cmap)\n",
    "    print(topics_in_image)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
